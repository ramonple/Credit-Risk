{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97687bd0",
   "metadata": {},
   "source": [
    "# Early Warning System (EWS) \n",
    "\n",
    "This notebook builds a small, *bank-style* Early Warning System (EWS) using **customer-month** behavioural data.\n",
    "It focuses on:\n",
    "- **Rolling window features** (trend, volatility, worst behaviour)\n",
    "- **Rule-based alerts** (operationally interpretable)\n",
    "- **Optional PD-style model** comparison (logistic regression)\n",
    "- **Monitoring outputs** (alerts over time, segment drilldowns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afba802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d1757",
   "metadata": {},
   "source": [
    "## 1) Generate synthetic customer-month behavioural data\n",
    "\n",
    "Each row is one **account-month**. We'll simulate typical credit card / revolving credit signals:\n",
    "- Utilisation\n",
    "- Payment ratio (payment / statement)\n",
    "- Missed payment flag\n",
    "- DPD (days past due) bucket\n",
    "- Balance and credit limit\n",
    "- segment (product, channel -> can use for monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704df37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_credit_panel(\n",
    "    n_customers=5000,\n",
    "    n_months=24,\n",
    "    start=\"2023-01-31\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Simulate a customer-month panel with behaviour signals and an outcome.\n",
    "\n",
    "    Outcome: default_next_3m (proxy for serious delinquency/default risk).\n",
    "    \"\"\"\n",
    "    start_date = pd.to_datetime(start)\n",
    "    dates = pd.date_range(start_date, periods=n_months, freq=\"M\")\n",
    "\n",
    "    # Customer-level static attributes\n",
    "    customer_id = np.arange(n_customers)\n",
    "\n",
    "    product = np.random.choice([\"Classic\", \"Rewards\", \"Premium\"], size=n_customers, p=[0.55, 0.35, 0.10])\n",
    "    channel = np.random.choice([\"Branch\", \"Online\", \"Partner\"], size=n_customers, p=[0.30, 0.55, 0.15])\n",
    "    risk_band = np.random.choice([\"A\", \"B\", \"C\", \"D\"], size=n_customers, p=[0.35, 0.35, 0.20, 0.10])\n",
    "\n",
    "    # Credit limits vary by risk band (higher band => higher limits)\n",
    "    band_limit_mu = {\"A\": 7000, \"B\": 5000, \"C\": 3500, \"D\": 2500}\n",
    "    limit = np.array([max(800, np.random.normal(band_limit_mu[b], 900)) for b in risk_band])\n",
    "    limit = np.round(limit, 0)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Latent \"financial stress\" baseline per customer (higher => worse)\n",
    "    band_stress = {\"A\": 0.10, \"B\": 0.20, \"C\": 0.32, \"D\": 0.45}\n",
    "    base_stress = np.array([np.random.beta(2, 10) + band_stress[b] for b in risk_band])\n",
    "    base_stress = np.clip(base_stress, 0, 1)\n",
    "\n",
    "    # Simulate month-by-month behaviour with persistence\n",
    "    util_prev = np.random.beta(2, 5, size=n_customers)\n",
    "    pay_prev = np.clip(np.random.normal(0.90, 0.12, size=n_customers), 0, 1)\n",
    "\n",
    "    dpd_prev = np.zeros(n_customers, dtype=int)  # 0, 30, 60, 90+\n",
    "    bal_prev = util_prev * limit\n",
    "\n",
    "    for t, d in enumerate(dates):\n",
    "        # Macro cycle / seasonality bump (small, but adds realism)\n",
    "        macro = 0.05 * np.sin(2 * np.pi * (t / 12))\n",
    "\n",
    "        # Utilization tends to increase with stress and previous utilization\n",
    "        util = (\n",
    "            0.65 * util_prev\n",
    "            + 0.25 * base_stress\n",
    "            + 0.10 * np.random.beta(2, 5, size=n_customers)\n",
    "            + macro\n",
    "        )\n",
    "        util = np.clip(util, 0, 1.4)  # allow >100% occasionally (overlimit)\n",
    "\n",
    "        # Payment ratio decreases with stress and higher utilization\n",
    "        pay = (\n",
    "            0.60 * pay_prev\n",
    "            + 0.35 * (1 - base_stress)\n",
    "            - 0.20 * np.maximum(util - 0.8, 0)\n",
    "            + 0.05 * np.random.normal(0, 1, size=n_customers)\n",
    "        )\n",
    "        pay = np.clip(pay, 0, 1.2)\n",
    "\n",
    "        # Missed payment probability increases if pay ratio is low or stress high\n",
    "        p_miss = 0.03 + 0.25 * (1 - np.clip(pay, 0, 1)) + 0.20 * base_stress + 0.10 * np.maximum(util - 0.9, 0)\n",
    "        p_miss = np.clip(p_miss, 0, 0.9)\n",
    "        missed_payment = (np.random.rand(n_customers) < p_miss).astype(int)\n",
    "\n",
    "        # DPD bucket transitions: missed payment pushes to higher bucket, good pay can cure\n",
    "        dpd = dpd_prev.copy()\n",
    "        # If missed, migrate upward; if already delinquent, can worsen\n",
    "        migrate_up = missed_payment == 1\n",
    "        dpd[migrate_up & (dpd_prev == 0)] = 30\n",
    "        dpd[migrate_up & (dpd_prev == 30)] = 60\n",
    "        dpd[migrate_up & (dpd_prev == 60)] = 90\n",
    "        dpd[migrate_up & (dpd_prev == 90)] = 90\n",
    "\n",
    "        # Cure: if not missed and paying reasonably, may improve\n",
    "        cure = (missed_payment == 0) & (pay > 0.6)\n",
    "        dpd[cure & (dpd_prev == 30)] = 0\n",
    "        dpd[cure & (dpd_prev == 60)] = 30\n",
    "        dpd[cure & (dpd_prev == 90)] = 60\n",
    "\n",
    "        # Balance follows utilization and can be noisy\n",
    "        balance = util * limit + np.random.normal(0, 120, size=n_customers)\n",
    "        balance = np.clip(balance, 0, None)\n",
    "\n",
    "        # Outcome risk: probability of serious delinquency within next 3m\n",
    "        # Increase with dpd, persistent high utilization, low payment, missed payments, stress, and macro\n",
    "        score = (\n",
    "            -3.8\n",
    "            + 1.8 * (dpd >= 30).astype(int)\n",
    "            + 2.4 * (dpd >= 60).astype(int)\n",
    "            + 3.0 * (dpd >= 90).astype(int)\n",
    "            + 2.0 * np.maximum(util - 0.85, 0)\n",
    "            + 2.2 * np.maximum(0.7 - np.clip(pay, 0, 1), 0)\n",
    "            + 1.2 * missed_payment\n",
    "            + 1.3 * base_stress\n",
    "            + 0.6 * macro\n",
    "        )\n",
    "        p_default = 1 / (1 + np.exp(-score))\n",
    "        default_next_3m = (np.random.rand(n_customers) < p_default).astype(int)\n",
    "\n",
    "        # Append rows\n",
    "        rows.append(pd.DataFrame({\n",
    "            \"customer_id\": customer_id,\n",
    "            \"date\": d,\n",
    "            \"product\": product,\n",
    "            \"channel\": channel,\n",
    "            \"risk_band\": risk_band,\n",
    "            \"credit_limit\": limit,\n",
    "            \"balance\": balance,\n",
    "            \"utilization\": balance / limit,\n",
    "            \"payment_ratio\": pay,\n",
    "            \"missed_payment\": missed_payment,\n",
    "            \"dpd_bucket\": dpd,\n",
    "            \"default_next_3m\": default_next_3m,\n",
    "        }))\n",
    "\n",
    "        # Update state\n",
    "        util_prev = np.clip(util, 0, 1.4)\n",
    "        pay_prev = np.clip(pay, 0, 1.2)\n",
    "        dpd_prev = dpd\n",
    "        bal_prev = balance\n",
    "\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    df = df.sort_values([\"customer_id\", \"date\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = simulate_credit_panel(n_customers=6000, n_months=24, start=\"2023-01-31\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ded91",
   "metadata": {},
   "source": [
    "### Quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df[\"date\"].min(), \"→\", df[\"date\"].max())\n",
    "df[[\"utilization\", \"payment_ratio\", \"missed_payment\", \"dpd_bucket\", \"default_next_3m\"]].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23390553",
   "metadata": {},
   "source": [
    "## 2) Rolling feature engineering (customer level)\n",
    "\n",
    "We build features that are typical in credit risk:\n",
    "- Rolling mean (recent behaviour)\n",
    "- Rolling max/min (worst behaviour)\n",
    "- Rolling sums (counts)\n",
    "- Rolling volatility (std)\n",
    "- Deterioration trend (short window - long window)\n",
    "\n",
    "> In production, these features are usually computed from monthly snapshots, bureau refreshes, or transaction aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dd123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper ordering\n",
    "df = df.sort_values([\"customer_id\", \"date\"]).copy()\n",
    "\n",
    "g = df.groupby(\"customer_id\", sort=False)\n",
    "\n",
    "# Rolling windows (in months)\n",
    "W_SHORT = 3\n",
    "W_LONG = 6\n",
    "W_XLONG = 12\n",
    "\n",
    "# Rolling means\n",
    "df[\"util_3m_avg\"] = g[\"utilization\"].rolling(W_SHORT).mean().reset_index(level=0, drop=True)\n",
    "df[\"util_6m_avg\"] = g[\"utilization\"].rolling(W_LONG).mean().reset_index(level=0, drop=True)\n",
    "df[\"pay_3m_avg\"]  = g[\"payment_ratio\"].rolling(W_SHORT).mean().reset_index(level=0, drop=True)\n",
    "df[\"pay_6m_avg\"]  = g[\"payment_ratio\"].rolling(W_LONG).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Rolling worst behaviour\n",
    "df[\"util_6m_max\"] = g[\"utilization\"].rolling(W_LONG).max().reset_index(level=0, drop=True)\n",
    "df[\"pay_6m_min\"]  = g[\"payment_ratio\"].rolling(W_LONG).min().reset_index(level=0, drop=True)\n",
    "\n",
    "# Rolling counts\n",
    "df[\"miss_3m_sum\"] = g[\"missed_payment\"].rolling(W_SHORT).sum().reset_index(level=0, drop=True)\n",
    "df[\"miss_6m_sum\"] = g[\"missed_payment\"].rolling(W_LONG).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# Rolling volatility\n",
    "df[\"pay_6m_std\"]  = g[\"payment_ratio\"].rolling(W_LONG).std().reset_index(level=0, drop=True)\n",
    "\n",
    "# Trend / deterioration features\n",
    "df[\"util_trend_3m_vs_12m\"] = df[\"util_3m_avg\"] - g[\"utilization\"].rolling(W_XLONG).mean().reset_index(level=0, drop=True)\n",
    "df[\"pay_trend_3m_vs_12m\"]  = df[\"pay_3m_avg\"]  - g[\"payment_ratio\"].rolling(W_XLONG).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# DPD-related rolling (any delinquency in window)\n",
    "df[\"any_dpd30_6m\"] = g[\"dpd_bucket\"].rolling(W_LONG).apply(lambda x: int(np.any(x >= 30)), raw=False).reset_index(level=0, drop=True)\n",
    "df[\"any_dpd60_12m\"] = g[\"dpd_bucket\"].rolling(W_XLONG).apply(lambda x: int(np.any(x >= 60)), raw=False).reset_index(level=0, drop=True)\n",
    "\n",
    "# Keep rows where long windows exist\n",
    "feat_cols = [\n",
    "    \"util_3m_avg\",\"util_6m_avg\",\"pay_3m_avg\",\"pay_6m_avg\",\n",
    "    \"util_6m_max\",\"pay_6m_min\",\"miss_3m_sum\",\"miss_6m_sum\",\n",
    "    \"pay_6m_std\",\"util_trend_3m_vs_12m\",\"pay_trend_3m_vs_12m\",\n",
    "    \"any_dpd30_6m\",\"any_dpd60_12m\"\n",
    "]\n",
    "\n",
    "model_df = df.dropna(subset=feat_cols + [\"default_next_3m\"]).copy()\n",
    "model_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fdfd9",
   "metadata": {},
   "source": [
    "## 3) Rule-based EWS alerts (interpretable)\n",
    "\n",
    "Banks often start with a **transparent ruleset**, then compare to a model.\n",
    "\n",
    "We'll create a simple ruleset that flags accounts if behaviour deteriorates:\n",
    "- Very high utilization recently or worst-case\n",
    "- Poor payment ratio recently\n",
    "- Multiple missed payments in last 6 months\n",
    "- Recent delinquency (DPD)\n",
    "\n",
    "You can tune thresholds to hit an operational target (e.g., alerts <= 3% of active accounts per month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rule thresholds (tune these)\n",
    "TH_UTIL_MAX = 0.95\n",
    "TH_PAY_AVG  = 0.65\n",
    "TH_MISS_6M  = 2\n",
    "TH_UTIL_TREND = 0.12  # short-term utilization rising vs long history\n",
    "\n",
    "# Alert rules\n",
    "model_df[\"alert_rule\"] = (\n",
    "    (model_df[\"util_6m_max\"] >= TH_UTIL_MAX) & (model_df[\"pay_3m_avg\"] <= TH_PAY_AVG)\n",
    ") | (\n",
    "    (model_df[\"miss_6m_sum\"] >= TH_MISS_6M)\n",
    ") | (\n",
    "    (model_df[\"any_dpd30_6m\"] == 1)\n",
    ") | (\n",
    "    (model_df[\"util_trend_3m_vs_12m\"] >= TH_UTIL_TREND)\n",
    ")\n",
    "\n",
    "model_df[\"alert_rule\"] = model_df[\"alert_rule\"].astype(int)\n",
    "\n",
    "# Basic performance: alerts vs outcome\n",
    "y_true = model_df[\"default_next_3m\"].astype(int)\n",
    "y_alert = model_df[\"alert_rule\"].astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_alert)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp) if (tp + fp) else np.nan\n",
    "recall = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "alert_rate = y_alert.mean()\n",
    "\n",
    "print(f\"Alert rate: {alert_rate:.3%}\")\n",
    "print(f\"Precision (default | alert): {precision:.3%}\")\n",
    "print(f\"Recall (capture of defaults): {recall:.3%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25c51a",
   "metadata": {},
   "source": [
    "### Alerts over time (monitoring view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = (\n",
    "    model_df.groupby(\"date\")\n",
    "    .agg(\n",
    "        accounts=(\"customer_id\",\"nunique\"),\n",
    "        alert_rate=(\"alert_rule\",\"mean\"),\n",
    "        default_rate=(\"default_next_3m\",\"mean\")\n",
    "    )\n",
    ")\n",
    "\n",
    "monthly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8595d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(monthly.index, monthly[\"alert_rate\"], label=\"Alert rate\")\n",
    "plt.plot(monthly.index, monthly[\"default_rate\"], label=\"Default (next 3m) rate\")\n",
    "plt.title(\"EWS Monitoring: Alert Rate vs Default Rate Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe5fee",
   "metadata": {},
   "source": [
    "### Segment drilldown (who is getting flagged?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac8ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = (\n",
    "    model_df.groupby([\"risk_band\",\"product\"])\n",
    "    .agg(\n",
    "        n_accounts=(\"customer_id\",\"nunique\"),\n",
    "        alert_rate=(\"alert_rule\",\"mean\"),\n",
    "        default_rate=(\"default_next_3m\",\"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"risk_band\",\"product\"])\n",
    ")\n",
    "\n",
    "seg.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee157d",
   "metadata": {},
   "source": [
    "## 4) Optional: Model-based risk score (Logistic Regression)\n",
    "\n",
    "Here we build a simple PD-style model using the rolling features, with a **time-based split** (train on early months, test on later months).\n",
    "\n",
    "This is closer to how credit models are validated in practice than random splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "cutoff = model_df[\"date\"].quantile(0.70)  # ~70% earliest months train\n",
    "train = model_df[model_df[\"date\"] <= cutoff].copy()\n",
    "test  = model_df[model_df[\"date\"] > cutoff].copy()\n",
    "\n",
    "X_train = train[feat_cols]\n",
    "y_train = train[\"default_next_3m\"].astype(int)\n",
    "\n",
    "X_test = test[feat_cols]\n",
    "y_test = test[\"default_next_3m\"].astype(int)\n",
    "\n",
    "# Simple logistic regression (baseline PD model)\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "test[\"pd_score\"] = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, test[\"pd_score\"])\n",
    "ap  = average_precision_score(y_test, test[\"pd_score\"])\n",
    "\n",
    "print(\"Cutoff date:\", pd.to_datetime(cutoff).date())\n",
    "print(f\"Test ROC AUC: {auc:.3f}\")\n",
    "print(f\"Test Avg Precision (PR AUC): {ap:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d40a1",
   "metadata": {},
   "source": [
    "### Compare operationally: pick a score threshold that matches the rule alert rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_alert_rate = model_df[\"alert_rule\"].mean()\n",
    "\n",
    "# Threshold = score quantile so that % flagged ≈ rule-based alert rate\n",
    "thr = test[\"pd_score\"].quantile(1 - target_alert_rate)\n",
    "test[\"alert_model\"] = (test[\"pd_score\"] >= thr).astype(int)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, test[\"alert_model\"])\n",
    "tn, fp, fn, tp = cm2.ravel()\n",
    "precision_m = tp / (tp + fp) if (tp + fp) else np.nan\n",
    "recall_m = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "\n",
    "print(f\"Rule-based alert rate (overall): {target_alert_rate:.3%}\")\n",
    "print(f\"Model threshold (test): {thr:.4f}\")\n",
    "print(f\"Model alert rate (test): {test['alert_model'].mean():.3%}\")\n",
    "print(f\"Model precision: {precision_m:.3%}\")\n",
    "print(f\"Model recall: {recall_m:.3%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c04e61",
   "metadata": {},
   "source": [
    "### Curves (ROC and Precision-Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103de976",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, test[\"pd_score\"])\n",
    "prec, rec, _ = precision_recall_curve(y_test, test[\"pd_score\"])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.title(\"ROC Curve (Test)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec, prec)\n",
    "plt.title(\"Precision-Recall Curve (Test)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534e89a",
   "metadata": {},
   "source": [
    "### Feature importance (model coefficients)\n",
    "\n",
    "This is a lightweight way to explain what drives risk in the model (useful for interviews and governance-style storytelling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33642c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame({\n",
    "    \"feature\": feat_cols,\n",
    "    \"coef\": lr.coef_[0]\n",
    "}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "coef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ebd39",
   "metadata": {},
   "source": [
    "## 5) EWS output table (what an analyst would hand to Risk Ops)\n",
    "\n",
    "This is a monthly ranked alert list with:\n",
    "- Rule alert\n",
    "- Model PD score\n",
    "- Key drivers\n",
    "\n",
    "In a real setting you'd join identifiers, collections strategy, and contactability flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the latest month in test period for a 'current' alert list\n",
    "latest_month = test[\"date\"].max()\n",
    "alerts_latest = test[test[\"date\"] == latest_month].copy()\n",
    "\n",
    "# Rank by model score; include both alert types\n",
    "alerts_latest = alerts_latest.sort_values(\"pd_score\", ascending=False)\n",
    "\n",
    "cols_out = [\n",
    "    \"customer_id\",\"date\",\"risk_band\",\"product\",\"channel\",\n",
    "    \"alert_rule\",\"alert_model\",\"pd_score\",\n",
    "    \"utilization\",\"util_3m_avg\",\"util_6m_max\",\"util_trend_3m_vs_12m\",\n",
    "    \"payment_ratio\",\"pay_3m_avg\",\"pay_6m_min\",\"pay_6m_std\",\n",
    "    \"missed_payment\",\"miss_6m_sum\",\"dpd_bucket\",\"any_dpd30_6m\",\n",
    "    \"default_next_3m\"\n",
    "]\n",
    "\n",
    "alerts_latest[cols_out].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393cee7",
   "metadata": {},
   "source": [
    "## 6) Next improvements (if you want to extend)\n",
    "\n",
    "Ideas to make this *even more bank/fintech realistic*:\n",
    "\n",
    "- **Calibration:** Calibrate PD scores (Platt / isotonic) and show calibration plot.\n",
    "- **Reject inference:** Simulate accept/reject and adjust labels.\n",
    "- **Champion/Challenger:** Compare rules vs model vs hybrid strategy.\n",
    "- **Cost-sensitive optimization:** Optimize thresholds based on expected loss (ECL proxy).\n",
    "- **Explainability:** Add SHAP for tree models (if you choose LightGBM/XGBoost).\n",
    "- **Production-friendly code:** Move simulation + feature engineering into `src/` modules.\n",
    "\n",
    "---\n",
    "\n",
    "### Minimal `requirements.txt`\n",
    "```\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "scikit-learn\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
